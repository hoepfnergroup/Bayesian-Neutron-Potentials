{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29f87d26",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccea46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math, Optimization and Stats. Packages\n",
    "import numpy as np                         \n",
    "from scipy import interpolate           \n",
    "import torch as torch  \n",
    "from scipy.optimize import minimize\n",
    "import emcee\n",
    "import time\n",
    "import corner\n",
    "\n",
    "# Plotting packages and settings\n",
    "import matplotlib.pyplot as plt  \n",
    "from matplotlib import colors\n",
    "from matplotlib import rc\n",
    "from matplotlib.pyplot import figure\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['DejaVu Sans'],'size':12})\n",
    "rc('mathtext',**{'default':'regular'})\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "get_ipython().run_line_magic('config', \"InlineBackend.figure_format = 'retina'\")\n",
    "# from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "#                                                   mark_inset)\n",
    "\n",
    "# Data Management\n",
    "import pandas as pd\n",
    "from pickle import dump, load  \n",
    "\n",
    "# Paralellization Packages and settings\n",
    "import dask\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "mp.set_start_method('fork')\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ad7fc",
   "metadata": {},
   "source": [
    "## Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4bfc18-c20e-4b2e-b4d5-3a9b03a2fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading experimental data...\n",
      "Success!!!\n",
      "tensor([[1.8502, 0.8571],\n",
      "        [1.8502, 0.7965],\n",
      "        [1.8502, 0.7438],\n",
      "        [1.8502, 0.6977],\n",
      "        [1.8925, 0.8571],\n",
      "        [1.8925, 0.7965],\n",
      "        [1.8925, 0.7438],\n",
      "        [1.8925, 0.6977],\n",
      "        [1.9330, 0.8571],\n",
      "        [1.9330, 0.7965],\n",
      "        [1.9330, 0.7438],\n",
      "        [1.9330, 0.6977],\n",
      "        [1.9718, 0.8571],\n",
      "        [1.9718, 0.7965],\n",
      "        [1.9718, 0.7438],\n",
      "        [1.9718, 0.6977],\n",
      "        [1.7291, 0.8010],\n",
      "        [1.8614, 0.9102],\n",
      "        [1.9428, 1.0521]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading experimental data...\")\n",
    "input_dict = load(open('exp_data/experimental_data_NEW.p', 'rb'))\n",
    "xs_exp = torch.tensor(input_dict['exp_params'])\n",
    "sqs_exp = torch.tensor(input_dict['sqs'])\n",
    "rdfs_exp = torch.tensor(input_dict['rdfs'])\n",
    "print(\"Success!!!\")\n",
    "print(xs_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63469c30",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8ddc431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Success!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading training data...\")\n",
    "input_dict = load(open('training_data/train_data.p', 'rb'))\n",
    "xd = torch.tensor(input_dict['xs'])\n",
    "sqs = torch.tensor(input_dict['sqs'])\n",
    "rdfs = torch.tensor(input_dict['rdfs'])\n",
    "print(\"Success!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb8208",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cc71ac9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def se_kernel(x1, x2, l, width):\n",
    "    K = width**2 * torch.exp(-(torch.cdist(x1/l,x2/l,p=2)**2)/2)\n",
    "    return K\n",
    "\n",
    "def local_surrogate(Xi, Xd, l, width, y, KddInv, μd):\n",
    "    V     = torch.stack([((n/(n-6))*((n/6)**((6)/(n-6))))*e*((s/r_pr)**n - (s/r_pr)**6) for n,s,e in zip(Xi[:,0],Xi[:,1],Xi[:,2])])\n",
    "    pmf_μ = torch.exp(-V/kbT)\n",
    "    μ    = torch.zeros([len(Xi), qnum])\n",
    "    for i in range (len(pmf_μ)):\n",
    "        μ[i]  = rdf2sq2(r_pr, pmf_μ[i], q, ρ) + 1    \n",
    "    Kid = se_kernel(Xi, Xd, l, width)\n",
    "    return (μ +(Kid @ KddInv) @ (y-μd)).T\n",
    "\n",
    "def local_surrogate1(Xi, Xd, l, width, y, KddInv):   \n",
    "    Kid = se_kernel(Xi, Xd, l, width)\n",
    "    return (1 +(Kid @ KddInv) @ (y-1)).T\n",
    "\n",
    "def rdf2sq2(r, rdf, q, ρ):\n",
    "    import numpy as np\n",
    "    dr = r[1] - r[0] \n",
    "    sq   = torch.zeros(len(q))\n",
    "    for j in range (len(q)):\n",
    "        sq[j] = (4*np.pi*ρ*np.trapz(r*(rdf-1)*np.sin(q[j]*r),dx = dr)/q[j])\n",
    "    return sq   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "069bf16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qmin = 1.25\n",
      "qmax = 30.698908169815425\n",
      "Δq = tensor(0.1253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1262705/1073679/ipykernel_4028722/197537984.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Xd = torch.tensor(xd).float()\n",
      "/scratch/local/u1262705/1073679/ipykernel_4028722/197537984.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(sqs).float()\n"
     ]
    }
   ],
   "source": [
    "N_particles = 1_000\n",
    "name = \"A\"\n",
    "timestep = 0.0025 # 48.#### fs\n",
    "kbT = 1\n",
    "ρ = 0.1\n",
    "nsims = 960\n",
    "\n",
    "rmax = (0.95/2)*((N_particles/ρ)**(1/3))\n",
    "rmin = 0\n",
    "rnum = 250\n",
    "r = np.linspace(rmin,rmax,rnum)\n",
    "\n",
    "#assume atom size of ~2.5 A^-1\n",
    "qmax = np.pi/(2.5*(rmax - rmin)/rnum) #qmax in reduced space is (π/Δr)*1/2.5\n",
    "qmin = 1.25                           #qmin in reduced space is qmin for standard diffractometers * 2.5 A\n",
    "qnum = 236                            #qnum selected so that the spacing is approximately 0.05A^{-1} for a 2.5 A particle\n",
    "q = torch.linspace(qmin,qmax,qnum) \n",
    "print('qmin =', qmin)\n",
    "print('qmax =', qmax)\n",
    "print('Δq =', q[1]- q[0])\n",
    "\n",
    "#Limit the training set to liquid-like region\n",
    "Xd = torch.tensor(xd).float()\n",
    "y = torch.tensor(sqs).float()\n",
    "\n",
    "n = len(Xd)\n",
    "η = len(q)\n",
    "\n",
    "index = torch.arange(0,len(Xd),1)\n",
    "\n",
    "#from hyperparameter training and model validation\n",
    "arr = [3.38224890e+00, 1.88830504e-01, 1.16976918e-01, 1.37565712e-01,1.37362647e-06]\n",
    "l = torch.tensor([arr[0],arr[1],arr[2]]).float()\n",
    "w = torch.tensor(arr[3]).float()\n",
    "σn = torch.tensor(arr[4]).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb23d19",
   "metadata": {},
   "source": [
    "## Prior Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935274c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "μ_n = 3\n",
    "σ_n = 1\n",
    "prior_n_dist = torch.distributions.normal.Normal(μ_n, σ_n)\n",
    "def log_prior_n(n):\n",
    "    return prior_n_dist.log_prob(n)\n",
    "    \n",
    "μ_σ = 2\n",
    "σ_σ = 1\n",
    "prior_σ_dist = torch.distributions.normal.Normal(μ_σ, σ_σ)\n",
    "def log_prior_σ(σ):\n",
    "    return prior_σ_dist.log_prob(σ)\n",
    "\n",
    "μ_ϵ = 0.7\n",
    "σ_ϵ = 1.5\n",
    "prior_ϵ_dist = torch.distributions.normal.Normal(μ_ϵ, σ_ϵ)\n",
    "def log_prior_ϵ(ϵ):\n",
    "    return prior_ϵ_dist.log_prob(ϵ)\n",
    "\n",
    "μ_σn = 0\n",
    "σ_σn = 1.5\n",
    "prior_σn_dist = torch.distributions.normal.Normal(μ_σn, σ_σn)\n",
    "def log_prior_σn(σn):\n",
    "    return prior_σn_dist.log_prob(σn)\n",
    "    \n",
    "def log_prior(pos):\n",
    "    return log_prior_n(pos[0]) + log_prior_σ(pos[1]) + log_prior_ϵ(pos[2]) + log_prior_σn(pos[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a02b9",
   "metadata": {},
   "source": [
    "## Prior Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1489032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set data\n",
    "Xd = xd.float()\n",
    "y = sqs.float()\n",
    "\n",
    "# Compute subset GP prediction over prior predictive set\n",
    "Kdd = se_kernel(Xd,Xd,l,w) + torch.eye(len(Xd))*σn\n",
    "KddInv = torch.linalg.inv(Kdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada9e810-a838-41f2-8e6d-a60e550278a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# exp_index = 15\n",
    "# sq_exp = sqs_exp[exp_index]\n",
    "# mie_exp = xs_exp[exp_index]\n",
    "# print(\"Exp Params:\",xs_exp[exp_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fdbcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replicates = 3\n",
    "# noise = np.random.normal(0,0.003,(replicates,len(sq_exp)))\n",
    "# pos = torch.tensor([12.0500,  1.9167,  0.1833, 0.009])\n",
    "# surr = local_surrogate1(pos[:3].unsqueeze(dim=0),Xd,l, w, y, KddInv).squeeze(dim=1)\n",
    "# for n in noise:\n",
    "#     plt.plot(q,sq_exp+n)\n",
    "# plt.plot(q, surr,linestyle='dashed')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2557cb6",
   "metadata": {},
   "source": [
    "# Posterior Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c44a13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = load(open('training_data/hyperparameter/hyperParams_laplace.p', 'rb'))\n",
    "# μ_hp = input_dict['mean']\n",
    "# cov_hp = input_dict['cov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a201aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_posterior(pos):\n",
    "    prior_θ = log_prior(pos)\n",
    "    pos = pos.exp()\n",
    "    pos[0] += 6\n",
    "    ssq_noisless = (local_surrogate1(pos[:3].unsqueeze(dim=0),Xd,l, w, y, KddInv).squeeze(dim=1) - sq_exp).repeat(int(replicates),1)\n",
    "    ssq = torch.sum((ssq_noisless - noise)**2)\n",
    "    LH = - ssq/(2*((pos[3])**(2))) - replicates*qnum*torch.log(pos[3]) - (replicates*qnum/2)*np.log(2*np.pi)\n",
    "    return prior_θ + LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "623fcd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scipy_log_posterior(pos):\n",
    "#     posTensor = torch.tensor(pos).float()\n",
    "#     out = -log_posterior(posTensor)\n",
    "#     return out \n",
    "\n",
    "def log_posterior_emcee(pos):\n",
    "    posTensor = torch.tensor(pos).float()\n",
    "    out = log_posterior(posTensor)\n",
    "    return out \n",
    "\n",
    "# bnds_n = ((None, None),(None, None),(None, None),(None,None))\n",
    "# out = minimize(scipy_log_posterior, (np.log(12), np.log(1.5), np.log(0.3), np.log(0.0001)),method='Nelder-Mead', options={'disp': True},bounds=bnds_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474cf2e",
   "metadata": {},
   "source": [
    "## Posterior Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d614c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp Params: tensor([1.8502, 0.8571], dtype=torch.float64)\n",
      "Starting MCMC Run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15168/200000 [31:30<5:58:05,  8.60it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 13%|█▎        | 25934/200000 [53:18<5:34:28,  8.67it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 20%|██        | 40972/200000 [1:24:52<5:08:39,  8.59it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 28%|██▊       | 55853/200000 [1:56:13<4:51:52,  8.23it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 35%|███▌      | 70857/200000 [2:28:40<4:16:37,  8.39it/s]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  7%|▋         | 13916/200000 [28:14<5:56:13,  8.71it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 14%|█▍        | 28401/200000 [57:48<5:32:32,  8.60it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 21%|██        | 42366/200000 [1:26:47<5:15:29,  8.33it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 28%|██▊       | 56592/200000 [1:56:42<4:38:54,  8.57it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "noise_arr = [0.005, 0.0075, 0.01, 0.02, 0.05, 0.1]\n",
    "\n",
    "for i in range (len(sqs_exp)):\n",
    "    for j in range (len(noise_arr)):\n",
    "        sq_exp = sqs_exp[i]\n",
    "        mie_exp = xs_exp[i]\n",
    "        print(\"Exp Params:\",xs_exp[i])\n",
    "\n",
    "        replicates = 4\n",
    "        noise = np.random.normal(0,noise_arr[j],(replicates,len(sq_exp)))\n",
    "\n",
    "        # Create an initial position for the MCMC walkers\n",
    "        ndim, nwalkers = 4, 160 # Make nwalkers = mp.cpu_count * 2 \n",
    "        p0 = np.ones((nwalkers, ndim))\n",
    "\n",
    "        # Set up the backend\n",
    "        # Don't forget to clear it in case the file already exists\n",
    "        filename = \"results/reactor_NEW/exp_\" + str(i) + \"unc_\" + str(j) + \".h5\"\n",
    "\n",
    "        p0[:,0] = np.random.normal(μ_n, σ_n, nwalkers)\n",
    "        p0[:,1] = np.random.normal(μ_σ, σ_σ, nwalkers)\n",
    "        p0[:,2] = np.random.normal(μ_ϵ, σ_ϵ, nwalkers)\n",
    "        p0[:,3] = np.random.normal(μ_σn, σ_σn, nwalkers)\n",
    "\n",
    "        backend = emcee.backends.HDFBackend(filename)\n",
    "        backend.reset(nwalkers, ndim)\n",
    "\n",
    "        # Use pool to parallelize calculation\n",
    "        print('Starting MCMC Run...')\n",
    "        with Pool() as pool:\n",
    "            #Create a sampler to run MCMC\n",
    "\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, log_posterior_emcee, pool = pool, backend = backend)\n",
    "\n",
    "            max_n = 200000\n",
    "\n",
    "            # We'll track how the average autocorrelation time estimate changes\n",
    "            index = 0\n",
    "            autocorr = np.empty(max_n)\n",
    "\n",
    "            # This will be useful to testing convergence\n",
    "            old_tau = np.inf\n",
    "\n",
    "            # Now we'll sample for up to max_n steps\n",
    "            for sample in sampler.sample(p0, iterations=max_n, progress=True, store=True, tune=True):\n",
    "                # Only check convergence every 100 steps\n",
    "                if sampler.iteration % 1000:\n",
    "                    continue\n",
    "\n",
    "                # Compute the autocorrelation time so far\n",
    "                # Using tol=0 means that we'll always get an estimate even\n",
    "                # if it isn't trustworthy\n",
    "                tau = sampler.get_autocorr_time(tol=0)\n",
    "                autocorr[index] = np.mean(tau)\n",
    "                index += 1\n",
    "\n",
    "                # Check convergence\n",
    "                converged = np.all(tau * 100 < sampler.iteration)\n",
    "                converged &= np.all(np.abs(old_tau - tau) / tau < 0.01)\n",
    "                if converged:\n",
    "                    break\n",
    "                old_tau = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc47119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2015e071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
